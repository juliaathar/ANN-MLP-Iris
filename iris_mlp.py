# -*- coding: utf-8 -*-
"""Iris_MLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UzySVWg93KD7XEw9HZJHeVLRtKQVQFq7

# Multilayer Perceptron

---


### Utilizando dataset Iris:
https://archive.ics.uci.edu/dataset/53/iris
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Carregar o dataset Iris
iris = load_iris()
X = iris.data  # Atributos: comprimento/largura de p√©talas e s√©palas
y = iris.target  # Classes: 0, 1, 2 (setosa, versicolor, virginica)

# Normaliza√ß√£o dos dados (muito importante para redes neurais!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Separar os dados em treino e teste (80% treino, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Criar o modelo com camadas densas (fully connected)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),  # 4 entradas -> 10 neur√¥nios
    tf.keras.layers.Dense(8, activation='relu'),  # camada escondida
    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes -> sa√≠da softmax
])

# Compilar o modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Treinar o modelo
history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))

# Avaliar o modelo
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nAcur√°cia no conjunto de teste: {accuracy:.2f}")

# Visualizar o hist√≥rico de treinamento
plt.plot(history.history['accuracy'], label='Treino')
plt.plot(history.history['val_accuracy'], label='Valida√ß√£o')
plt.title('Acur√°cia por √âpoca')
plt.xlabel('√âpoca')
plt.ylabel('Acur√°cia')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd

# Criar uma planilha Excel
with pd.ExcelWriter("pesos_do_modelo.xlsx") as writer:
    for i, layer in enumerate(model.layers):
        weights, biases = layer.get_weights()  # pesos e bias da camada
        df_weights = pd.DataFrame(weights)
        df_biases = pd.DataFrame(biases.reshape(1, -1))  # reshape para 1 linha

        # Salvar pesos
        df_weights.to_excel(writer, sheet_name=f"Layer_{i+1}_Pesos", index=False)
        # Salvar bias
        df_biases.to_excel(writer, sheet_name=f"Layer_{i+1}_Bias", index=False)

print("‚úÖ Arquivo 'pesos_do_modelo.xlsx' criado com sucesso!")

import pandas as pd

# Converter os dados de entrada e r√≥tulos em DataFrame
df_X_train = pd.DataFrame(X_train, columns=iris.feature_names)
df_y_train = pd.DataFrame(y_train, columns=["target"])

# Concatenar os dados e o r√≥tulo na mesma tabela
df_treino = pd.concat([df_X_train, df_y_train], axis=1)

# Salvar em Excel
df_treino.to_excel("dados_treino.xlsx", index=False)

# Fazer download no Colab
from google.colab import files
files.download("dados_treino.xlsx")

import pandas as pd
import tensorflow as tf

# Escolher o √≠ndice da amostra para testar (ex: a primeira amostra do treino)
indice = 1

# Exibir os dados de entrada e o r√≥tulo real
entrada = X_train[indice]
rotulo_real = y_train[indice]

# Criar DataFrame com os dados formatados
df_entrada = pd.DataFrame([entrada], columns=iris.feature_names)
df_entrada["target"] = rotulo_real
print("üì• Dados de entrada usados na infer√™ncia:")
display(df_entrada)

# Fazer infer√™ncia (predi√ß√£o)
entrada_reshape = entrada.reshape(1, -1)  # Ajustar para o formato (1, n_features)
saida_softmax = model.predict(entrada_reshape)
classe_prevista = tf.argmax(saida_softmax, axis=1).numpy()[0]

# Mostrar resultado da infer√™ncia
print("\nüîç Sa√≠da da softmax:", saida_softmax)
print("‚úÖ Classe prevista:", classe_prevista)
print("üéØ Classe real:    ", rotulo_real)